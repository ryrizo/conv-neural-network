{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** A large portion of this code is taken from Tensorflow tutorials. Most adjustments were to change the conv-net architecture or to get the code to work with my AWS server setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size defined as: 128\n",
      "Data Dir defined as: /home/ubuntu/Notebooks/cifar10_data\n",
      "Use Fp16 defined as: False\n",
      "Train dir defined as: /tmp/cifar10_train\n",
      "Max Steps defined as: 10000\n",
      "Log device placement defined as: False\n",
      "Eval dir defined as: /tmp/cifar10_eval\n",
      "Eval data defined as: test\n",
      "Checkpoint dir defined as: /tmp/cifar10_train\n",
      "Eval interval secs defined as: 60\n",
      "Num examples defined as: 10000\n",
      "Run once defined as: False\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.models.image.cifar10 import cifar10_input\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import time\n",
    "import numpy as np\n",
    "from six.moves import urllib, xrange  # pylint: disable=redefined-builtin\n",
    "import math\n",
    "\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "try:\n",
    "    tf.app.flags.DEFINE_integer('batch_size', 128, 'Number of images per batch')\n",
    "except:\n",
    "    FLAGS.batch_size = 128\n",
    "    print(\"Batch size defined as: %s\" % str(FLAGS.batch_size))\n",
    "try:\n",
    "    tf.app.flags.DEFINE_string('data_dir', '/home/ubuntu/Notebooks/cifar10_data',\"Path to the CIFAR-10 data directory.\")\n",
    "except:\n",
    "    FLAGS.data_dir = '/home/ubuntu/Notebooks/cifar10_data'\n",
    "    print(\"Data Dir defined as: %s\" % str(FLAGS.data_dir))\n",
    "try:\n",
    "    tf.app.flags.DEFINE_boolean('use_fp16', False,\"Train the model using fp16.\")\n",
    "except:\n",
    "    FLAGS.use_fp16 = False\n",
    "    print(\"Use Fp16 defined as: %s\" % str(FLAGS.use_fp16))\n",
    "try:\n",
    "    tf.app.flags.DEFINE_string('train_dir', '/tmp/cifar10_train',\"\"\"Directory where to  \"\"\")\n",
    "except:\n",
    "    FLAGS.train_dir = '/tmp/cifar10_train'\n",
    "    print(\"Train dir defined as: %s\" % str(FLAGS.train_dir))\n",
    "try:\n",
    "    tf.app.flags.DEFINE_integer('max_steps', 10000,\"\"\"Number of batches to run.\"\"\")\n",
    "except:\n",
    "    FLAGS.max_steps = 10000\n",
    "    print(\"Max Steps defined as: %s\" % str(FLAGS.max_steps))\n",
    "try:\n",
    "    tf.app.flags.DEFINE_boolean('log_device_placement', False,\"\"\"Whether to log device placement.\"\"\")\n",
    "except:\n",
    "    FLAGS.log_device_placement = False\n",
    "    print(\"Log device placement defined as: %s\" % str(FLAGS.log_device_placement))\n",
    "try:\n",
    "    tf.app.flags.DEFINE_string('eval_dir', '/tmp/cifar10_eval',\n",
    "                           \"\"\"Directory where to write event logs.\"\"\")\n",
    "except:\n",
    "    FLAGS.eval_dir = '/tmp/cifar10_eval'\n",
    "    print(\"Eval dir defined as: %s\" % str(FLAGS.eval_dir))\n",
    "try:\n",
    "    tf.app.flags.DEFINE_string('eval_data', 'test',\n",
    "                           \"\"\"Either 'test' or 'train_eval'.\"\"\")\n",
    "except:\n",
    "    FLAGS.eval_data = 'test'\n",
    "    print(\"Eval data defined as: %s\" % str(FLAGS.eval_data))\n",
    "try:\n",
    "    tf.app.flags.DEFINE_string('checkpoint_dir', '/tmp/cifar10_train',\n",
    "                           \"\"\"Directory where to read model checkpoints.\"\"\")\n",
    "except:\n",
    "    FLAGS.checkpoint_dir = '/tmp/cifar10_train'\n",
    "    print(\"Checkpoint dir defined as: %s\" % str(FLAGS.checkpoint_dir))\n",
    "try:\n",
    "    tf.app.flags.DEFINE_integer('eval_interval_secs', 60 * 5,\n",
    "                            \"\"\"How often to run the eval.\"\"\")\n",
    "except:\n",
    "    FLAGS.eval_interval_secs = 60\n",
    "    print(\"Eval interval secs defined as: %s\" % str(FLAGS.eval_interval_secs))\n",
    "try:\n",
    "    tf.app.flags.DEFINE_integer('num_examples', 10000,\n",
    "                            \"\"\"Number of examples to run.\"\"\")\n",
    "except:\n",
    "    FLAGS.num_examples = 10000\n",
    "    print(\"Num examples defined as: %s\" % str(FLAGS.num_examples))\n",
    "try:\n",
    "    tf.app.flags.DEFINE_boolean('run_once', False,\n",
    "                         \"\"\"Whether to run eval only once.\"\"\")\n",
    "except:    \n",
    "    FLAGS.run_once = False\n",
    "    print(\"Run once defined as: %s\" % str(FLAGS.run_once))\n",
    "\n",
    "    \n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "IMAGE_SIZE = cifar10_input.IMAGE_SIZE\n",
    "NUM_CLASSES = cifar10_input.NUM_CLASSES\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n",
    "\n",
    "\n",
    "# Constants describing the training process.\n",
    "MOVING_AVERAGE_DECAY = 0.9999     # The decay to use for the moving average.\n",
    "NUM_EPOCHS_PER_DECAY = 350.0      # Epochs after which learning rate decays.\n",
    "LEARNING_RATE_DECAY_FACTOR = 0.1  # Learning rate decay factor.\n",
    "INITIAL_LEARNING_RATE = 0.1       # Initial learning rate.\n",
    "\n",
    "TOWER_NAME = 'tower'\n",
    "\n",
    "DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download CIFAR10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maybe_download_and_extract():\n",
    "  \"\"\"Download and extract the tarball from Alex's website.\"\"\"\n",
    "  dest_directory = DATA_DIR\n",
    "  if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "  filename = DATA_URL.split('/')[-1]\n",
    "  filepath = os.path.join(dest_directory, filename)\n",
    "  if not os.path.exists(filepath):\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename,\n",
    "          float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()\n",
    "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "\n",
    "#maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for reading in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def distorted_inputs():\n",
    "  \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "  Raises:\n",
    "    ValueError: If no data_dir\n",
    "  \"\"\"\n",
    "  if not FLAGS.data_dir:\n",
    "    raise ValueError('Please supply a data_dir')\n",
    "  data_dir = os.path.join(FLAGS.data_dir, 'cifar-10-batches-bin')\n",
    "  images, labels = cifar10_input.distorted_inputs(data_dir=data_dir,\n",
    "                                                  batch_size=FLAGS.batch_size)\n",
    "  if FLAGS.use_fp16:\n",
    "    images = tf.cast(images, tf.float16)\n",
    "    labels = tf.cast(labels, tf.float16)\n",
    "  return images, labels\n",
    "\n",
    "\n",
    "def inputs(eval_data):\n",
    "  \"\"\"Construct input for CIFAR evaluation using the Reader ops.\n",
    "  Args:\n",
    "    eval_data: bool, indicating if one should use the train or eval data set.\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "  Raises:\n",
    "    ValueError: If no data_dir\n",
    "  \"\"\"\n",
    "  if not FLAGS.data_dir:\n",
    "    raise ValueError('Please supply a data_dir')\n",
    "  data_dir = os.path.join(FLAGS.data_dir, 'cifar-10-batches-bin')\n",
    "  images, labels = cifar10_input.inputs(eval_data=eval_data,\n",
    "                                        data_dir=data_dir,\n",
    "                                        batch_size=FLAGS.batch_size)\n",
    "  if FLAGS.use_fp16:\n",
    "    images = tf.cast(images, tf.float16)\n",
    "    labels = tf.cast(labels, tf.float16)\n",
    "  return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _activation_summary(x):\n",
    "  \"\"\"Helper to create summaries for activations.\n",
    "  Creates a summary that provides a histogram of activations.\n",
    "  Creates a summary that measures the sparsity of activations.\n",
    "  Args:\n",
    "    x: Tensor\n",
    "  Returns:\n",
    "    nothing\n",
    "  \"\"\"\n",
    "  # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training\n",
    "  # session. This helps the clarity of presentation on tensorboard.\n",
    "  tensor_name = re.sub('%s_[0-9]*/' % TOWER_NAME, '', x.op.name)\n",
    "  tf.histogram_summary(tensor_name + '/activations', x)\n",
    "  tf.scalar_summary(tensor_name + '/sparsity', tf.nn.zero_fraction(x))\n",
    "    \n",
    "def _variable_on_cpu(name, shape, initializer):\n",
    "  \"\"\"Helper to create a Variable stored on CPU memory.\n",
    "  Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    initializer: initializer for Variable\n",
    "  Returns:\n",
    "    Variable Tensor\n",
    "  \"\"\"\n",
    "  with tf.device('/cpu:0'):\n",
    "    dtype = tf.float16 if FLAGS.use_fp16 else tf.float32\n",
    "    var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)\n",
    "  return var\n",
    "\n",
    "\n",
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "  \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "  Note that the Variable is initialized with a truncated normal distribution.\n",
    "  A weight decay is added only if one is specified.\n",
    "  Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    stddev: standard deviation of a truncated Gaussian\n",
    "    wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "        decay is not added for this Variable.\n",
    "  Returns:\n",
    "    Variable Tensor\n",
    "  \"\"\"\n",
    "  dtype = tf.float16 if FLAGS.use_fp16 else tf.float32\n",
    "  var = _variable_on_cpu(\n",
    "      name,\n",
    "      shape,\n",
    "      tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))\n",
    "  if wd is not None:\n",
    "    weight_decay = tf.mul(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "    tf.add_to_collection('losses', weight_decay)\n",
    "  return var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(images):\n",
    "    #Architecture [INPUT -> CONV -> RELU -> POOL -> FC]\n",
    "    \n",
    "    # Convolution Layer. Stride = 1 Shape = 3x3 Filters = 12\n",
    "    #tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        # Kernel shape is \n",
    "        kernel = _variable_with_weight_decay('weights',\n",
    "                                             shape=[3, 3, 3, 12],\n",
    "                                             stddev=5e-2,\n",
    "                                             wd=0.0)\n",
    "        conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME') # I think same padding is correct. out should be 32x32x12\n",
    "        biases = _variable_on_cpu('biases', [12], tf.constant_initializer(0.0))\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        # Relu Activation Unit\n",
    "        conv1 = tf.nn.relu(bias, name=scope.name) # \n",
    "        _activation_summary(conv1)\n",
    "    \n",
    "    # Pooling \n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool1')\n",
    "    \n",
    "    #Fully Connected Layer: in 16x16x12 out 1x1x10\n",
    "    with tf.variable_scope('local1') as scope:\n",
    "        # Move everything into depth so we can perform a single matrix multiply.\n",
    "        reshape = tf.reshape(pool1, [FLAGS.batch_size, -1])\n",
    "        dim = reshape.get_shape()[1].value\n",
    "        weights = _variable_with_weight_decay('weights', shape=[dim, 10],\n",
    "                                              stddev=0.04, wd=0.004)\n",
    "        biases = _variable_on_cpu('biases', [10], tf.constant_initializer(0.1))\n",
    "        local1 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "        _activation_summary(local1)\n",
    "\n",
    "  # softmax, i.e. softmax(WX + b)\n",
    "    with tf.variable_scope('softmax') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', [10, NUM_CLASSES],\n",
    "                                              stddev=1/10.0, wd=0.0)\n",
    "        biases = _variable_on_cpu('biases', [NUM_CLASSES],\n",
    "                                  tf.constant_initializer(0.0))\n",
    "        #softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "        softmax = tf.nn.softmax(tf.matmul(local1, weights) + biases, name=scope.name)\n",
    "        _activation_summary(softmax)\n",
    "    \n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inference_cuda(images):\n",
    "  \"\"\"Build the CIFAR-10 model.\n",
    "  Args:\n",
    "    images: Images returned from distorted_inputs() or inputs().\n",
    "  Returns:\n",
    "    Logits.\n",
    "  \"\"\"\n",
    "  # We instantiate all variables using tf.get_variable() instead of\n",
    "  # tf.Variable() in order to share variables across multiple GPU training runs.\n",
    "  # If we only ran this model on a single GPU, we could simplify this function\n",
    "  # by replacing all instances of tf.get_variable() with tf.Variable().\n",
    "  #\n",
    "  # conv1\n",
    "  with tf.variable_scope('conv1') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[5, 5, 3, 64],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv1 = tf.nn.relu(bias, name=scope.name)\n",
    "    _activation_summary(conv1)\n",
    "\n",
    "  # pool1\n",
    "  pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool1')\n",
    "  # norm1\n",
    "  norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm1')\n",
    "\n",
    "  # conv2\n",
    "  with tf.variable_scope('conv2') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[5, 5, 64, 64],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv2 = tf.nn.relu(bias, name=scope.name)\n",
    "    _activation_summary(conv2)\n",
    "\n",
    "  # norm2\n",
    "  norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm2')\n",
    "  # pool2\n",
    "  pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],\n",
    "                         strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "\n",
    "  # local3\n",
    "  with tf.variable_scope('local3') as scope:\n",
    "    # Move everything into depth so we can perform a single matrix multiply.\n",
    "    reshape = tf.reshape(pool2, [FLAGS.batch_size, -1])\n",
    "    dim = reshape.get_shape()[1].value\n",
    "    weights = _variable_with_weight_decay('weights', shape=[dim, 384],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1))\n",
    "    local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "    _activation_summary(local3)\n",
    "\n",
    "  # local4\n",
    "  with tf.variable_scope('local4') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', shape=[384, 192],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))\n",
    "    local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)\n",
    "    _activation_summary(local4)\n",
    "\n",
    "  # softmax, i.e. softmax(WX + b)\n",
    "  with tf.variable_scope('softmax_linear') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', [192, NUM_CLASSES],\n",
    "                                          stddev=1/192.0, wd=0.0)\n",
    "    biases = _variable_on_cpu('biases', [NUM_CLASSES],\n",
    "                              tf.constant_initializer(0.0))\n",
    "    #softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "    softmax = tf.nn.softmax(tf.matmul(local4, weights) + biases, name=scope.name)\n",
    "    _activation_summary(softmax)\n",
    "\n",
    "  return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss(logits, labels):\n",
    "  \"\"\"Add L2Loss to all the trainable variables.\n",
    "  Add summary for \"Loss\" and \"Loss/avg\".\n",
    "  Args:\n",
    "    logits: Logits from inference().\n",
    "    labels: Labels from distorted_inputs or inputs(). 1-D tensor\n",
    "            of shape [batch_size]\n",
    "  Returns:\n",
    "    Loss tensor of type float.\n",
    "  \"\"\"\n",
    "  # Calculate the average cross entropy loss across the batch.\n",
    "  labels = tf.cast(labels, tf.int64)\n",
    "  cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "      logits, labels, name='cross_entropy_per_example')\n",
    "  cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "  tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "  # The total loss is defined as the cross entropy loss plus all of the weight\n",
    "  # decay terms (L2 loss).\n",
    "  return tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "\n",
    "def _add_loss_summaries(total_loss):\n",
    "  \"\"\"Add summaries for losses in CIFAR-10 model.\n",
    "  Generates moving average for all losses and associated summaries for\n",
    "  visualizing the performance of the network.\n",
    "  Args:\n",
    "    total_loss: Total loss from loss().\n",
    "  Returns:\n",
    "    loss_averages_op: op for generating moving averages of losses.\n",
    "  \"\"\"\n",
    "  # Compute the moving average of all individual losses and the total loss.\n",
    "  loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
    "  losses = tf.get_collection('losses')\n",
    "  loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
    "\n",
    "  # Attach a scalar summary to all individual losses and the total loss; do the\n",
    "  # same for the averaged version of the losses.\n",
    "  for l in losses + [total_loss]:\n",
    "    # Name each loss as '(raw)' and name the moving average version of the loss\n",
    "    # as the original loss name.\n",
    "    tf.scalar_summary(l.op.name +' (raw)', l)\n",
    "    tf.scalar_summary(l.op.name, loss_averages.average(l))\n",
    "\n",
    "  return loss_averages_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_step(total_loss, global_step):\n",
    "  \"\"\"Train CIFAR-10 model.\n",
    "  Create an optimizer and apply to all trainable variables. Add moving\n",
    "  average for all trainable variables.\n",
    "  Args:\n",
    "    total_loss: Total loss from loss().\n",
    "    global_step: Integer Variable counting the number of training steps\n",
    "      processed.\n",
    "  Returns:\n",
    "    train_op: op for training.\n",
    "  \"\"\"\n",
    "  # Variables that affect learning rate.\n",
    "  num_batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / FLAGS.batch_size\n",
    "  decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)\n",
    "\n",
    "  # Decay the learning rate exponentially based on the number of steps.\n",
    "  lr = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\n",
    "                                  global_step,\n",
    "                                  decay_steps,\n",
    "                                  LEARNING_RATE_DECAY_FACTOR,\n",
    "                                  staircase=True)\n",
    "  tf.scalar_summary('learning_rate', lr)\n",
    "\n",
    "  # Generate moving averages of all losses and associated summaries.\n",
    "  loss_averages_op = _add_loss_summaries(total_loss)\n",
    "\n",
    "  # Compute gradients.\n",
    "  with tf.control_dependencies([loss_averages_op]):\n",
    "    opt = tf.train.GradientDescentOptimizer(lr)\n",
    "    grads = opt.compute_gradients(total_loss)\n",
    "\n",
    "  # Apply gradients.\n",
    "  apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "  # Add histograms for trainable variables.\n",
    "  for var in tf.trainable_variables():\n",
    "    tf.histogram_summary(var.op.name, var)\n",
    "\n",
    "  # Add histograms for gradients.\n",
    "  for grad, var in grads:\n",
    "    if grad is not None:\n",
    "      tf.histogram_summary(var.op.name + '/gradients', grad)\n",
    "\n",
    "  # Track the moving averages of all trainable variables.\n",
    "  variable_averages = tf.train.ExponentialMovingAverage(\n",
    "      MOVING_AVERAGE_DECAY, global_step)\n",
    "  variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "  with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "    train_op = tf.no_op(name='train')\n",
    "\n",
    "  return train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "  \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    images, labels = distorted_inputs()\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    logits = inference(images)\n",
    "\n",
    "    # Calculate loss.\n",
    "    l2_loss = loss(logits, labels)\n",
    "\n",
    "    # Build a Graph that trains the model with one batch of examples and\n",
    "    # updates the model parameters.\n",
    "    train_op = train_step(l2_loss, global_step)\n",
    "\n",
    "    # Create a saver.\n",
    "    saver = tf.train.Saver(tf.all_variables())\n",
    "\n",
    "    # Build the summary operation based on the TF collection of Summaries.\n",
    "    summary_op = tf.merge_all_summaries()\n",
    "\n",
    "    # Build an initialization operation to run below.\n",
    "    init = tf.initialize_all_variables()\n",
    "\n",
    "    # Start running operations on the Graph.\n",
    "    sess = tf.Session(config=tf.ConfigProto(\n",
    "        log_device_placement=FLAGS.log_device_placement))\n",
    "    sess.run(init)\n",
    "\n",
    "    # Start the queue runners.\n",
    "    tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir, sess.graph)\n",
    "\n",
    "    for step in xrange(FLAGS.max_steps):\n",
    "      start_time = time.time()\n",
    "      _, loss_value = sess.run([train_op, l2_loss])\n",
    "      duration = time.time() - start_time\n",
    "\n",
    "      assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "      if step % 10 == 0:\n",
    "        num_examples_per_step = FLAGS.batch_size\n",
    "        examples_per_sec = num_examples_per_step / duration\n",
    "        sec_per_batch = float(duration)\n",
    "\n",
    "        format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "                      'sec/batch)')\n",
    "        print (format_str % (datetime.now(), step, loss_value,\n",
    "                             examples_per_sec, sec_per_batch))\n",
    "\n",
    "      if step % 100 == 0:\n",
    "        summary_str = sess.run(summary_op)\n",
    "        summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "      # Save the model checkpoint periodically.\n",
    "      if step % 1000 == 0 or (step + 1) == FLAGS.max_steps:\n",
    "        checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')\n",
    "        saver.save(sess, checkpoint_path, global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(argv=None):  # pylint: disable=unused-argument\n",
    "  #cifar10.maybe_download_and_extract()\n",
    "  if tf.gfile.Exists(FLAGS.train_dir):\n",
    "    tf.gfile.DeleteRecursively(FLAGS.train_dir)\n",
    "  tf.gfile.MakeDirs(FLAGS.train_dir)\n",
    "  train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "2016-08-23 00:42:26.034512: step 0, loss = 2.35 (2.8 examples/sec; 44.938 sec/batch)\n",
      "2016-08-23 00:42:29.123954: step 10, loss = 2.35 (437.7 examples/sec; 0.292 sec/batch)\n",
      "2016-08-23 00:42:32.018382: step 20, loss = 2.35 (451.2 examples/sec; 0.284 sec/batch)\n",
      "2016-08-23 00:42:34.902179: step 30, loss = 2.34 (453.4 examples/sec; 0.282 sec/batch)\n",
      "2016-08-23 00:42:37.798457: step 40, loss = 2.34 (428.4 examples/sec; 0.299 sec/batch)\n",
      "2016-08-23 00:42:40.674738: step 50, loss = 2.34 (458.1 examples/sec; 0.279 sec/batch)\n",
      "2016-08-23 00:42:43.566977: step 60, loss = 2.34 (441.9 examples/sec; 0.290 sec/batch)\n",
      "2016-08-23 00:42:46.437777: step 70, loss = 2.34 (455.5 examples/sec; 0.281 sec/batch)\n",
      "2016-08-23 00:42:49.335399: step 80, loss = 2.34 (429.8 examples/sec; 0.298 sec/batch)\n",
      "2016-08-23 00:42:52.233289: step 90, loss = 2.34 (431.3 examples/sec; 0.297 sec/batch)\n",
      "2016-08-23 00:42:55.108576: step 100, loss = 2.34 (459.0 examples/sec; 0.279 sec/batch)\n",
      "2016-08-23 00:42:58.290014: step 110, loss = 2.34 (435.3 examples/sec; 0.294 sec/batch)\n",
      "2016-08-23 00:43:01.172075: step 120, loss = 2.34 (442.1 examples/sec; 0.290 sec/batch)\n",
      "2016-08-23 00:43:04.057428: step 130, loss = 2.34 (444.1 examples/sec; 0.288 sec/batch)\n",
      "2016-08-23 00:43:06.936407: step 140, loss = 2.34 (449.2 examples/sec; 0.285 sec/batch)\n",
      "2016-08-23 00:43:09.805658: step 150, loss = 2.33 (454.2 examples/sec; 0.282 sec/batch)\n",
      "2016-08-23 00:43:12.693718: step 160, loss = 2.33 (454.1 examples/sec; 0.282 sec/batch)\n",
      "2016-08-23 00:43:15.581525: step 170, loss = 2.33 (435.4 examples/sec; 0.294 sec/batch)\n",
      "2016-08-23 00:43:18.461109: step 180, loss = 2.33 (449.7 examples/sec; 0.285 sec/batch)\n",
      "2016-08-23 00:43:21.339655: step 190, loss = 2.32 (424.1 examples/sec; 0.302 sec/batch)\n",
      "2016-08-23 00:43:24.227285: step 200, loss = 2.32 (438.0 examples/sec; 0.292 sec/batch)\n",
      "2016-08-23 00:43:27.382982: step 210, loss = 2.32 (457.7 examples/sec; 0.280 sec/batch)\n",
      "2016-08-23 00:43:30.260739: step 220, loss = 2.30 (452.3 examples/sec; 0.283 sec/batch)\n",
      "2016-08-23 00:43:33.139456: step 230, loss = 2.31 (447.0 examples/sec; 0.286 sec/batch)\n",
      "2016-08-23 00:43:36.027642: step 240, loss = 2.32 (440.2 examples/sec; 0.291 sec/batch)\n",
      "2016-08-23 00:43:38.896147: step 250, loss = 2.29 (439.5 examples/sec; 0.291 sec/batch)\n",
      "2016-08-23 00:43:41.793175: step 260, loss = 2.33 (436.6 examples/sec; 0.293 sec/batch)\n",
      "2016-08-23 00:43:44.676096: step 270, loss = 2.29 (447.6 examples/sec; 0.286 sec/batch)\n",
      "2016-08-23 00:43:47.571156: step 280, loss = 2.28 (415.9 examples/sec; 0.308 sec/batch)\n",
      "2016-08-23 00:43:50.442748: step 290, loss = 2.30 (457.6 examples/sec; 0.280 sec/batch)\n",
      "2016-08-23 00:43:53.323862: step 300, loss = 2.26 (464.4 examples/sec; 0.276 sec/batch)\n",
      "2016-08-23 00:43:56.503723: step 310, loss = 2.29 (442.4 examples/sec; 0.289 sec/batch)\n",
      "2016-08-23 00:43:59.392455: step 320, loss = 2.27 (449.2 examples/sec; 0.285 sec/batch)\n",
      "2016-08-23 00:44:02.274742: step 330, loss = 2.27 (434.4 examples/sec; 0.295 sec/batch)\n",
      "2016-08-23 00:44:05.156927: step 340, loss = 2.30 (447.6 examples/sec; 0.286 sec/batch)\n",
      "2016-08-23 00:44:08.036009: step 350, loss = 2.27 (452.5 examples/sec; 0.283 sec/batch)\n",
      "2016-08-23 00:44:10.919108: step 360, loss = 2.27 (451.2 examples/sec; 0.284 sec/batch)\n",
      "2016-08-23 00:44:13.807186: step 370, loss = 2.26 (453.3 examples/sec; 0.282 sec/batch)\n",
      "2016-08-23 00:44:16.693986: step 380, loss = 2.25 (444.4 examples/sec; 0.288 sec/batch)\n",
      "2016-08-23 00:44:19.595600: step 390, loss = 2.25 (425.7 examples/sec; 0.301 sec/batch)\n",
      "2016-08-23 00:44:22.468739: step 400, loss = 2.24 (461.6 examples/sec; 0.277 sec/batch)\n",
      "2016-08-23 00:44:25.644114: step 410, loss = 2.19 (455.6 examples/sec; 0.281 sec/batch)\n",
      "2016-08-23 00:44:28.528626: step 420, loss = 2.24 (442.2 examples/sec; 0.289 sec/batch)\n",
      "2016-08-23 00:44:31.414447: step 430, loss = 2.24 (450.1 examples/sec; 0.284 sec/batch)\n",
      "2016-08-23 00:44:34.301876: step 440, loss = 2.25 (448.5 examples/sec; 0.285 sec/batch)\n",
      "2016-08-23 00:44:37.174440: step 450, loss = 2.27 (458.9 examples/sec; 0.279 sec/batch)\n",
      "2016-08-23 00:44:40.070022: step 460, loss = 2.26 (440.8 examples/sec; 0.290 sec/batch)\n",
      "2016-08-23 00:44:42.958932: step 470, loss = 2.27 (441.7 examples/sec; 0.290 sec/batch)\n",
      "2016-08-23 00:44:45.837729: step 480, loss = 2.24 (444.7 examples/sec; 0.288 sec/batch)\n",
      "2016-08-23 00:44:48.720405: step 490, loss = 2.27 (435.6 examples/sec; 0.294 sec/batch)\n",
      "2016-08-23 00:44:51.600836: step 500, loss = 2.21 (436.8 examples/sec; 0.293 sec/batch)\n",
      "2016-08-23 00:44:54.765675: step 510, loss = 2.26 (440.7 examples/sec; 0.290 sec/batch)\n",
      "2016-08-23 00:44:57.654389: step 520, loss = 2.20 (453.8 examples/sec; 0.282 sec/batch)\n",
      "2016-08-23 00:45:00.531911: step 530, loss = 2.22 (450.7 examples/sec; 0.284 sec/batch)\n",
      "2016-08-23 00:45:03.431012: step 540, loss = 2.26 (419.8 examples/sec; 0.305 sec/batch)\n",
      "2016-08-23 00:45:06.308599: step 550, loss = 2.20 (450.2 examples/sec; 0.284 sec/batch)\n",
      "2016-08-23 00:45:09.194026: step 560, loss = 2.24 (450.2 examples/sec; 0.284 sec/batch)\n",
      "2016-08-23 00:45:12.083783: step 570, loss = 2.24 (432.8 examples/sec; 0.296 sec/batch)\n",
      "2016-08-23 00:45:14.963629: step 580, loss = 2.21 (437.9 examples/sec; 0.292 sec/batch)\n",
      "2016-08-23 00:45:17.849824: step 590, loss = 2.19 (429.2 examples/sec; 0.298 sec/batch)\n",
      "2016-08-23 00:45:20.727237: step 600, loss = 2.21 (444.5 examples/sec; 0.288 sec/batch)\n",
      "2016-08-23 00:45:23.905807: step 610, loss = 2.22 (447.5 examples/sec; 0.286 sec/batch)\n",
      "2016-08-23 00:45:26.805094: step 620, loss = 2.26 (429.3 examples/sec; 0.298 sec/batch)\n",
      "2016-08-23 00:45:29.686844: step 630, loss = 2.26 (449.2 examples/sec; 0.285 sec/batch)\n",
      "2016-08-23 00:45:32.578401: step 640, loss = 2.21 (454.6 examples/sec; 0.282 sec/batch)\n",
      "2016-08-23 00:45:35.469076: step 650, loss = 2.24 (428.0 examples/sec; 0.299 sec/batch)\n",
      "2016-08-23 00:45:38.349265: step 660, loss = 2.18 (436.8 examples/sec; 0.293 sec/batch)\n",
      "2016-08-23 00:45:41.233108: step 670, loss = 2.20 (437.0 examples/sec; 0.293 sec/batch)\n",
      "2016-08-23 00:45:44.128102: step 680, loss = 2.21 (429.6 examples/sec; 0.298 sec/batch)\n",
      "2016-08-23 00:45:46.993254: step 690, loss = 2.21 (460.6 examples/sec; 0.278 sec/batch)\n",
      "2016-08-23 00:45:49.892949: step 700, loss = 2.23 (432.1 examples/sec; 0.296 sec/batch)\n",
      "2016-08-23 00:45:53.058698: step 710, loss = 2.22 (463.2 examples/sec; 0.276 sec/batch)\n",
      "2016-08-23 00:45:55.934715: step 720, loss = 2.23 (426.9 examples/sec; 0.300 sec/batch)\n",
      "2016-08-23 00:45:58.815229: step 730, loss = 2.22 (439.3 examples/sec; 0.291 sec/batch)\n",
      "2016-08-23 00:46:01.687720: step 740, loss = 2.21 (435.9 examples/sec; 0.294 sec/batch)\n",
      "2016-08-23 00:46:04.561009: step 750, loss = 2.25 (433.1 examples/sec; 0.296 sec/batch)\n",
      "2016-08-23 00:46:07.434832: step 760, loss = 2.20 (458.0 examples/sec; 0.279 sec/batch)\n",
      "2016-08-23 00:46:10.327618: step 770, loss = 2.22 (429.6 examples/sec; 0.298 sec/batch)\n",
      "2016-08-23 00:46:13.201934: step 780, loss = 2.18 (445.9 examples/sec; 0.287 sec/batch)\n",
      "2016-08-23 00:46:16.081423: step 790, loss = 2.19 (441.4 examples/sec; 0.290 sec/batch)\n",
      "2016-08-23 00:46:18.965491: step 800, loss = 2.25 (445.4 examples/sec; 0.287 sec/batch)\n",
      "2016-08-23 00:46:22.136073: step 810, loss = 2.21 (430.0 examples/sec; 0.298 sec/batch)\n",
      "2016-08-23 00:46:25.032522: step 820, loss = 2.19 (419.8 examples/sec; 0.305 sec/batch)\n",
      "2016-08-23 00:46:27.902620: step 830, loss = 2.19 (434.9 examples/sec; 0.294 sec/batch)\n",
      "2016-08-23 00:46:30.785716: step 840, loss = 2.20 (446.7 examples/sec; 0.287 sec/batch)\n",
      "2016-08-23 00:46:33.678811: step 850, loss = 2.20 (441.9 examples/sec; 0.290 sec/batch)\n",
      "2016-08-23 00:46:36.575763: step 860, loss = 2.19 (450.5 examples/sec; 0.284 sec/batch)\n",
      "2016-08-23 00:46:39.445957: step 870, loss = 2.19 (450.3 examples/sec; 0.284 sec/batch)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-58ca95c5b364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-7c125781de6d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeleteRecursively\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-0318225ade40>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m       \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-08-22 01:12:57.451063: precision @ 1 = 0.817\n"
     ]
    }
   ],
   "source": [
    "def eval_once(saver, summary_writer, top_k_op, summary_op,pred):\n",
    "  \"\"\"Run Eval once.\n",
    "  Args:\n",
    "    saver: Saver.\n",
    "    summary_writer: Summary writer.\n",
    "    top_k_op: Top K op.\n",
    "    summary_op: Summary op.\n",
    "  \"\"\"\n",
    "  with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "      # Restores from checkpoint\n",
    "      saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "      # Assuming model_checkpoint_path looks something like:\n",
    "      #   /my-favorite-path/cifar10_train/model.ckpt-0,\n",
    "      # extract global_step from it.\n",
    "      global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "    else:\n",
    "      print('No checkpoint file found')\n",
    "      return\n",
    "\n",
    "    # Start the queue runners.\n",
    "    coord = tf.train.Coordinator()\n",
    "    try:\n",
    "      threads = []\n",
    "      for qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):\n",
    "        threads.extend(qr.create_threads(sess, coord=coord, daemon=True,\n",
    "                                         start=True))\n",
    "\n",
    "      num_iter = int(math.ceil(FLAGS.num_examples / FLAGS.batch_size))\n",
    "      true_count = 0  # Counts the number of correct predictions.\n",
    "      total_sample_count = num_iter * FLAGS.batch_size\n",
    "      step = 0\n",
    "      while step < num_iter and not coord.should_stop():\n",
    "        predictions = sess.run([top_k_op])\n",
    "        true_count += np.sum(predictions)\n",
    "        step += 1\n",
    "        \n",
    "      pred = pred + predictions\n",
    "      # Compute precision @ 1.\n",
    "      precision = true_count / total_sample_count\n",
    "      print('%s: precision @ 1 = %.3f' % (datetime.now(), precision))\n",
    "\n",
    "      summary = tf.Summary()\n",
    "      summary.ParseFromString(sess.run(summary_op))\n",
    "      summary.value.add(tag='Precision @ 1', simple_value=precision)\n",
    "      summary_writer.add_summary(summary, global_step)\n",
    "    except Exception as e:  # pylint: disable=broad-except\n",
    "      coord.request_stop(e)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads, stop_grace_period_secs=10)\n",
    "    return pred\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "  \"\"\"Eval CIFAR-10 for a number of steps.\"\"\"\n",
    "  with tf.Graph().as_default() as g:\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    eval_data = FLAGS.eval_data == 'test'\n",
    "    images, labels = inputs(eval_data=eval_data)\n",
    "    pred = list()\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    logits = inference(images)\n",
    "    \n",
    "    # Calculate predictions.\n",
    "    top_k_op = tf.nn.in_top_k(logits, labels, 1)\n",
    "\n",
    "    # Restore the moving average version of the learned variables for eval.\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "        MOVING_AVERAGE_DECAY)\n",
    "    variables_to_restore = variable_averages.variables_to_restore()\n",
    "    saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "    # Build the summary operation based on the TF collection of Summaries.\n",
    "    summary_op = tf.merge_all_summaries()\n",
    "\n",
    "    summary_writer = tf.train.SummaryWriter(FLAGS.eval_dir, g)\n",
    "\n",
    "    while True:\n",
    "      pred.append(eval_once(saver, summary_writer, top_k_op, summary_op, pred))\n",
    "      if FLAGS.run_once:\n",
    "        break\n",
    "      time.sleep(FLAGS.eval_interval_secs)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "FLAGS.run_once = True\n",
    "pred = evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([ True,  True, False, False,  True,  True,  True,  True, False,\n",
       "          True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         False,  True, False, False,  True,  True,  True,  True,  True,\n",
       "          True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "          True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "          True, False,  True, False,  True, False,  True,  True, False,\n",
       "         False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         False, False], dtype=bool)]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
